{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564b35ca-8699-49f3-a348-505267fb7224",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 01:12:47.221382: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc94da3-f099-46c5-aee5-427e356bea19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 01:12:49.672535: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-07 01:12:49.877438: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-07 01:12:49.880192: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-07 01:12:49.884294: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-07 01:12:49.886415: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-07 01:12:49.888476: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-07 01:12:50.103009: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-07 01:12:50.104992: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-07 01:12:50.106771: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-07 01:12:50.108513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13764 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting  ...\n",
      "Label: 0\n",
      "I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However  ...\n",
      "Label: 0\n",
      "Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Moun ...\n",
      "Label: 0\n",
      "This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful perf ...\n",
      "Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 01:12:51.499954: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-06-07 01:12:51.500637: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "raw_train_set, raw_valid_set= tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=[\"train[:90%]\", \"train[90%:]\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "train_set = raw_train_set.shuffle(5000, seed=42).batch(32).prefetch(1)\n",
    "valid_set = raw_valid_set.batch(32).prefetch(1)\n",
    "\n",
    "for review, label in raw_train_set.take(4):\n",
    "    print(review.numpy().decode(\"utf-8\")[:200], \"...\")\n",
    "    print(\"Label:\", label.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf817ef3-05cf-4b87-b945-ec162cc98191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 01:12:56.816361: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000\n",
    "text_vec_layer = layers.TextVectorization(max_tokens=vocab_size)\n",
    "text_vec_layer.adapt(train_set.map(lambda reviews, labels: reviews))\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(text_vec_layer)\n",
    "    model.add(layers.Embedding(vocab_size, hp.Int('embed_size', min_value=64, max_value=256, step=32), mask_zero=True))\n",
    "    \n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(layers.GRU(units=hp.Int(f'unit_{i}', min_value=64, max_value=256, step=32), return_sequences=True))\n",
    "    \n",
    "    model.add(layers.GRU(units=hp.Int('final_units', min_value=64, max_value=256, step=32)))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "    \n",
    "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop'])\n",
    "\n",
    "    if hp_optimizer == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
    "    elif hp_optimizer == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=hp_learning_rate)\n",
    "    elif hp_optimizer == 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=hp_learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa94586-e718-43db-80ed-aa22a97473b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 16m 13s]\n",
      "val_accuracy: 0.4927999973297119\n",
      "\n",
      "Best val_accuracy So Far: 0.8776000142097473\n",
      "Total elapsed time: 02h 28m 25s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first GRU layer is 128 with embedding size 64 and final units 160.\n",
      "The optimal learning rate for the optimizer is 0.001 with optimizer rmsprop.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,  # Increase the max_epochs\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='imdb_reviews'\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "tuner.search(train_set, validation_data=valid_set, epochs=20, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first GRU layer is {best_hps.get('unit_0')} with embedding size {best_hps.get('embed_size')} and final units {best_hps.get('final_units')}.\n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')} with optimizer {best_hps.get('optimizer')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7c443f-68e7-4862-84de-b650b7ca87c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5281 - loss: 0.6808\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67040, saving model to IMDBModel.keras\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 92ms/step - accuracy: 0.5282 - loss: 0.6807 - val_accuracy: 0.6704 - val_loss: 0.6522\n",
      "Epoch 2/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7534 - loss: 0.5242\n",
      "Epoch 2: val_accuracy improved from 0.67040 to 0.77760, saving model to IMDBModel.keras\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 90ms/step - accuracy: 0.7534 - loss: 0.5241 - val_accuracy: 0.7776 - val_loss: 0.4721\n",
      "Epoch 3/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8074 - loss: 0.4457\n",
      "Epoch 3: val_accuracy did not improve from 0.77760\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 90ms/step - accuracy: 0.8074 - loss: 0.4456 - val_accuracy: 0.6600 - val_loss: 0.5893\n",
      "Epoch 4/30\n",
      "\u001b[1m703/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8359 - loss: 0.3838\n",
      "Epoch 4: val_accuracy improved from 0.77760 to 0.85520, saving model to IMDBModel.keras\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 90ms/step - accuracy: 0.8359 - loss: 0.3837 - val_accuracy: 0.8552 - val_loss: 0.3371\n",
      "Epoch 5/30\n",
      "\u001b[1m703/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8720 - loss: 0.3142\n",
      "Epoch 5: val_accuracy improved from 0.85520 to 0.86200, saving model to IMDBModel.keras\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 91ms/step - accuracy: 0.8720 - loss: 0.3142 - val_accuracy: 0.8620 - val_loss: 0.3296\n",
      "Epoch 6/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8862 - loss: 0.2840\n",
      "Epoch 6: val_accuracy did not improve from 0.86200\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 90ms/step - accuracy: 0.8862 - loss: 0.2840 - val_accuracy: 0.8608 - val_loss: 0.3237\n",
      "Epoch 7/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8898 - loss: 0.2726\n",
      "Epoch 7: val_accuracy improved from 0.86200 to 0.87040, saving model to IMDBModel.keras\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 90ms/step - accuracy: 0.8898 - loss: 0.2726 - val_accuracy: 0.8704 - val_loss: 0.3123\n",
      "Epoch 8/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8984 - loss: 0.2581\n",
      "Epoch 8: val_accuracy did not improve from 0.87040\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 91ms/step - accuracy: 0.8984 - loss: 0.2581 - val_accuracy: 0.8468 - val_loss: 0.3580\n",
      "Epoch 9/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9013 - loss: 0.2492\n",
      "Epoch 9: val_accuracy improved from 0.87040 to 0.87120, saving model to IMDBModel.keras\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 90ms/step - accuracy: 0.9013 - loss: 0.2492 - val_accuracy: 0.8712 - val_loss: 0.3257\n",
      "Epoch 10/30\n",
      "\u001b[1m703/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9083 - loss: 0.2377\n",
      "Epoch 10: val_accuracy did not improve from 0.87120\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 90ms/step - accuracy: 0.9083 - loss: 0.2377 - val_accuracy: 0.8620 - val_loss: 0.3464\n",
      "Epoch 11/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9138 - loss: 0.2242\n",
      "Epoch 11: val_accuracy did not improve from 0.87120\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 90ms/step - accuracy: 0.9138 - loss: 0.2242 - val_accuracy: 0.8620 - val_loss: 0.3622\n",
      "Epoch 12/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9179 - loss: 0.2137\n",
      "Epoch 12: val_accuracy did not improve from 0.87120\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 90ms/step - accuracy: 0.9179 - loss: 0.2138 - val_accuracy: 0.8600 - val_loss: 0.3731\n",
      "Epoch 13/30\n",
      "\u001b[1m703/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9244 - loss: 0.2036\n",
      "Epoch 13: val_accuracy did not improve from 0.87120\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 90ms/step - accuracy: 0.9244 - loss: 0.2036 - val_accuracy: 0.8576 - val_loss: 0.3927\n",
      "Epoch 14/30\n",
      "\u001b[1m703/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9301 - loss: 0.1895\n",
      "Epoch 14: val_accuracy did not improve from 0.87120\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 90ms/step - accuracy: 0.9301 - loss: 0.1895 - val_accuracy: 0.8548 - val_loss: 0.4024\n",
      "Epoch 15/30\n",
      "\u001b[1m703/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9352 - loss: 0.1774\n",
      "Epoch 15: val_accuracy did not improve from 0.87120\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 90ms/step - accuracy: 0.9352 - loss: 0.1774 - val_accuracy: 0.8600 - val_loss: 0.4376\n",
      "Epoch 16/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9404 - loss: 0.1703\n",
      "Epoch 16: val_accuracy did not improve from 0.87120\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 89ms/step - accuracy: 0.9404 - loss: 0.1703 - val_accuracy: 0.8488 - val_loss: 0.4744\n",
      "Epoch 17/30\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9476 - loss: 0.1503\n",
      "Epoch 17: val_accuracy did not improve from 0.87120\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 89ms/step - accuracy: 0.9476 - loss: 0.1503 - val_accuracy: 0.8380 - val_loss: 0.4358\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    }
   ],
   "source": [
    "# Build and train the final model with the optimal hyperparameters\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'IMDBModel.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    validation_data=valid_set,\n",
    "    epochs=30,\n",
    "    callbacks=[checkpoint_cb, early_stop_cb]\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "model.save('savedModel.keras')\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
